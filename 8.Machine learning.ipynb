{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What exactly is a feature? Give an example to illustrate your point.\n",
    "Ans:- Examples of feature in a Sentence\n",
    "Noun This year's models include several new safety features. This camera has several features that make it easy to use. \n",
    "The car has some interesting new design features. His plan combines the best features of the earlier proposals. Her eyes \n",
    "are her best feature.\n",
    "\n",
    "2. What are the various circumstances in which feature construction is required?\n",
    "Ans: The features in your data will directly influence the predictive models you use and the results you can achieve. Your \n",
    "    results are dependent on many inter-dependent properties. You need great features that describe the structures inherent\n",
    "    in your data. Better features means flexibility.\n",
    "    \n",
    "3. Describe how nominal variables are encoded.\n",
    "Ans:- When we have a feature where variables are just names and there is no order or rank to this variable's feature.\n",
    "    For example: City of person lives in, Gender of person, Marital Status, etc… In the above example, We do not have any\n",
    "        order or rank, or sequence.\n",
    "        \n",
    "4. Describe how numeric features are converted to categorical features.\n",
    "Ans:- Converting categorical features into numeric features using domain knowledge. For example, we are given a list of \n",
    "    countries and say we know the distance to these countries from India then we can replace it with distance from India. \n",
    "    So, every country can be represented as its distance from India.\n",
    "    \n",
    "5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this\n",
    "approach?\n",
    "Ans:- Wrapper methods measure the “usefulness” of features based on the classifier performance. In contrast, the filter \n",
    "    methods pick up the intrinsic properties of the features (i.e., the “relevance” of the features) measured via \n",
    "    univariate statistics instead of cross-validation performance.\n",
    "\n",
    "The wrapper classification algorithms with joint dimensionality reduction and classification can also be used but these \n",
    "methods have high computation cost, lower discriminative power. Moreover, these methods depend on the efficient selection \n",
    "of classifiers for obtaining high accuracy\n",
    "\n",
    "6. When is a feature considered irrelevant? What can be said to quantify it?\n",
    "Ans:- We also want to remove any features that are not predictive or should not be considered for some other reason\n",
    "    (e.g. it is illegal to use the feature in the model). These are known as irrelevant features.\n",
    "    \n",
    "7. When is a function considered redundant? What criteria are used to identify features that could\n",
    "be redundant?\n",
    "Ans:- If two features {X1, X2} are highly correlated, then the two features become redundant features since they have same\n",
    "    information in terms of correlation measure. In other words, the correlation measure provides statistical association \n",
    "    between any given a pair of features.\n",
    "\n",
    "Minimum redundancy feature selection is an algorithm frequently used in a method to accurately identify characteristics of \n",
    "genes and phenotypes\n",
    "\n",
    "8. What are the various distance measurements used to determine feature similarity?\n",
    "Ans: Four of the most commonly used distance measures in machine learning are as follows:\n",
    "\n",
    ".Hamming Distance.\n",
    ".Euclidean Distance\n",
    ".Manhattan Distance.\n",
    "\n",
    "\n",
    "9. State difference between Euclidean and Manhattan distances?\n",
    "Ans: Euclidean & Hamming distances are used to measure similarity or dissimilarity between two sequences. Euclidean\n",
    "    distance is extensively applied in analysis of convolutional codes and Trellis codes.\n",
    "\n",
    "Hamming distance is frequently encountered in the analysis of block codes.\n",
    "\n",
    "10. Distinguish between feature transformation and feature selection.\n",
    "Ans: Feature selection is for filtering irrelevant or redundant features from your dataset. The key difference between \n",
    "    feature selection and extraction is that feature selection keeps a subset of the original features while feature \n",
    "    extraction creates brand new ones.\n",
    "    \n",
    "11. Make brief notes on any two of the following:\n",
    "    \n",
    "1.SVD (Standard Variable Diameter Diameter)\n",
    "    Ans:-\n",
    "Image result for 1.svd (standard variable diameter diameter) answers\n",
    "In linear algebra, the Singular Value Decomposition (SVD) of a matrix is a factorization of that matrix into three \n",
    "matrices. It has some interesting algebraic properties and conveys important geometrical and theoretical insights about\n",
    "linear transformations.\n",
    "\n",
    "2. Collection of features using a hybrid approach\n",
    "Ans:-\n",
    "    There are two main types of feature selection techniques: supervised and unsupervised, and supervised methods may be \n",
    "        divided into wrapper, filter and intrinsic.\n",
    "        \n",
    "3. The width of the silhouette\n",
    "Ans:- The Average Silhouette Width (ASW) of a clustering is ̄ a ( i ) is the average distance of to points in the cluster\n",
    "    to which it was assigned, and is the average distance of to the points in the nearest cluster to which it was not \n",
    "    assigned.\n",
    "    \n",
    "4. Receiver operating characteristic curve\n",
    "Ans:- The method that is mainly used for this process is the receiver operating characteristic (ROC) curve. The ROC curve \n",
    "    aims to classify a patient's disease state as either positive or negative based on test results and to find the optimal\n",
    "    cut-off value with the best diagnostic performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
